{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug sentence classification\n",
    "\n",
    "\n",
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import torch, io, gzip, json, random, argparse, os\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (BertTokenizer, BertConfig, AdamW, BertForSequenceClassification,\n",
    "        WarmupLinearSchedule)\n",
    "\n",
    "from arxiv_public_data.config import DIR_BASE, DIR_OUTPUT, DIR_FULLTEXT\n",
    "f_metadata = os.path.join(DIR_BASE, 'arxiv-metadata-oai-2019-03-01.json.gz')\n",
    "\n",
    "#Got these from Matt\n",
    "cat_map = {\n",
    "  \"astro-ph\": \"astro-ph\",\n",
    "  \"cond-mat\": \"cond-mat\",\n",
    "  \"cs\": \"cs\",\n",
    "  \"gr-qc\": \"gr-qc\",\n",
    "  \"hep-ex\": \"hep-ex\",\n",
    "  \"hep-lat\": \"hep-lat\",\n",
    "  \"hep-ph\": \"hep-ph\",\n",
    "  \"hep-th\": \"hep-th\",\n",
    "  \"math-ph\": \"math-ph\",\n",
    "  \"nlin\": \"nlin\",\n",
    "  \"nucl-ex\": \"nucl-ex\",\n",
    "  \"nucl-th\": \"nucl-th\",\n",
    "  \"physics\": \"physics\",\n",
    "  \"quant-ph\": \"quant-ph\",\n",
    "  \"math\": \"math\",\n",
    "  \"q-bio\": \"q-bio\",\n",
    "  \"q-fin\": \"q-fin\",\n",
    "  \"stat\": \"stat\",\n",
    "  \"eess\": \"eess\",\n",
    "  \"econ\": \"econ\",\n",
    "  \"acc-phys\": \"physics.acc-ph\",\n",
    "  \"adap-org\": \"nlin.AO\",\n",
    "  \"alg-geom\": \"math.AG\",\n",
    "  \"ao-sci\": \"physics.ao-ph\",\n",
    "  \"atom-ph\": \"physics.atom-ph\",\n",
    "  \"bayes-an\": \"physics.data-an\",\n",
    "  \"chao-dyn\": \"nlin.CD\",\n",
    "  \"chem-ph\": \"physics.chem-ph\",\n",
    "  \"cmp-lg\": \"cs.CL\",\n",
    "  \"comp-gas\": \"nlin.CG\",\n",
    "  \"dg-ga\": \"math.DG\",\n",
    "  \"funct-an\": \"math.FA\",\n",
    "  \"mtrl-th\": \"cond-mat.mtrl-sci\",\n",
    "  \"patt-sol\": \"nlin.PS\",\n",
    "  \"plasm-ph\": \"physics.plasm-ph\",\n",
    "  \"q-alg\": \"math.QA\",\n",
    "  \"solv-int\": \"nlin.SI\",\n",
    "  \"supr-con\": \"cond-mat.supr-con\"\n",
    "}\n",
    "\n",
    "\n",
    "# I should experiment with and without this\n",
    "def clean_doc(x):\n",
    "    x = x.lower()\n",
    "    x = x.replace('\\n',' ')\n",
    "    x = x.replace(' \" ',' ')\n",
    "    x = x.replace('\"','')\n",
    "    x = x.replace(\"'\", \"\")\n",
    "    x = x.replace(':',' ')\n",
    "    x = x.replace('?',' ')\n",
    "    x = x.replace('-',' ')\n",
    "    x = x.replace(',','')\n",
    "    x = x.replace('$',' $ ')\n",
    "    x = x.replace('.','')\n",
    "    x = x.replace('!',' ')\n",
    "    x = x.replace('(',' ')\n",
    "    x = x.replace(')',' ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_data(N, fname):\n",
    "    #fname ='/home/khev/research/arxiv-public-datasets/arxiv-data/arxiv-metadata-oai-2019-03-01.json.gz'\n",
    "    metadata = []\n",
    "    ctr = 0\n",
    "    with gzip.open(fname, 'rt', encoding='utf-8') as fin:\n",
    "        for row in fin.readlines():\n",
    "            metadata.append(json.loads(row))\n",
    "            ctr += 1\n",
    "            if ctr > N:\n",
    "                break\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def process_data(metadata, data_type='title'):\n",
    "    \"\"\"\n",
    "    data_type \\element ['title', 'abstract']\n",
    "    \"\"\"\n",
    "\n",
    "    sentences, labels, label_dict = [], [], {}\n",
    "    for m in metadata:\n",
    "\n",
    "        #sentences / titles\n",
    "        sentence = clean_doc(m[data_type])\n",
    "        \n",
    "        # We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "        sentence = \"[CLS] \" + sentence + \" [SEP]\" \n",
    "        sentences.append(sentence)\n",
    "\n",
    "        #category\n",
    "        category = m['categories'][0].split(' ')[0]\n",
    "\n",
    "        #Take only primary index: 'math.CO' --> 'math'\n",
    "        primaryCategories = False\n",
    "        if primaryCategories:\n",
    "            cutoff = len(category)\n",
    "            try:\n",
    "                cutoff = category.index('.')\n",
    "            except ValueError:\n",
    "                    pass\n",
    "            category = category[:cutoff]\n",
    "        \n",
    "        if category not in label_dict:\n",
    "            index = len(label_dict)\n",
    "            label_dict[category] = index  # e.g. {'hep-ph':2}\n",
    "        else:\n",
    "            index = label_dict[category]\n",
    "        labels.append(index)\n",
    "\n",
    "    return sentences, labels, label_dict\n",
    "\n",
    "\n",
    "def process_data_sub(metadata, data_type='title'):\n",
    "    \"\"\"\n",
    "    Same as above, except I merge categories that are the same\n",
    "    (origianl data in buggy: category names changed over times so have to be fixed)\n",
    "    \n",
    "    data_type='title' or 'abstract' or 'fulltext'\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    sentences, labels, label_dict = [], [], {}\n",
    "    for i, m in enumerate(metadata):\n",
    "\n",
    "        #sentences / titles\n",
    "        if data_type != 'fulltext':\n",
    "            sentence = clean_doc(m[data_type])\n",
    "        else:\n",
    "            sentence = load_ith_fulltext(i)  ###needs to be filled in\n",
    "            sentence = clean_doc(sentence)\n",
    "        \n",
    "        # We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "        sentence = \"[CLS] \" + sentence + \" [SEP]\" \n",
    "        sentences.append(sentence)\n",
    "\n",
    "        #category\n",
    "        category = m['categories'][0].split(' ')[0]\n",
    "        \n",
    "        #update cateogies -- apply matt's map\n",
    "        if category in cat_map:\n",
    "            category = cat_map[category]\n",
    "        \n",
    "        #Then add to the dics\n",
    "        if category not in label_dict:\n",
    "            index = len(label_dict)\n",
    "            label_dict[category] = index  # ex: {'hep-ph':0, 'math.CO:1',,}\n",
    "        else:\n",
    "            index = label_dict[category]\n",
    "        labels.append(index)\n",
    "\n",
    "    return sentences, labels, label_dict\n",
    "\n",
    "\n",
    "N, data_type = 10**7, 'title'\n",
    "metadata = load_data(N,f_metadata)\n",
    "sentences, labels, label_dict_new = process_data_sub(metadata, data_type=data_type)\n",
    "len(label_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, data_type = 10**7, 'title'\n",
    "metadata = load_data(N,f_metadata)\n",
    "sentences, labels, label_dict_old = process_data(metadata, data_type=data_type)\n",
    "len(label_dict_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'astro-ph': 'astro-ph',\n",
       " 'cond-mat': 'cond-mat',\n",
       " 'cs': 'cs',\n",
       " 'gr-qc': 'gr-qc',\n",
       " 'hep-ex': 'hep-ex',\n",
       " 'hep-lat': 'hep-lat',\n",
       " 'hep-ph': 'hep-ph',\n",
       " 'hep-th': 'hep-th',\n",
       " 'math-ph': 'math-ph',\n",
       " 'nlin': 'nlin',\n",
       " 'nucl-ex': 'nucl-ex',\n",
       " 'nucl-th': 'nucl-th',\n",
       " 'physics': 'physics',\n",
       " 'quant-ph': 'quant-ph',\n",
       " 'math': 'math',\n",
       " 'q-bio': 'q-bio',\n",
       " 'q-fin': 'q-fin',\n",
       " 'stat': 'stat',\n",
       " 'eess': 'eess',\n",
       " 'econ': 'econ',\n",
       " 'acc-phys': 'physics.acc-ph',\n",
       " 'adap-org': 'nlin.AO',\n",
       " 'alg-geom': 'math.AG',\n",
       " 'ao-sci': 'physics.ao-ph',\n",
       " 'atom-ph': 'physics.atom-ph',\n",
       " 'bayes-an': 'physics.data-an',\n",
       " 'chao-dyn': 'nlin.CD',\n",
       " 'chem-ph': 'physics.chem-ph',\n",
       " 'cmp-lg': 'cs.CL',\n",
       " 'comp-gas': 'nlin.CG',\n",
       " 'dg-ga': 'math.DG',\n",
       " 'funct-an': 'math.FA',\n",
       " 'mtrl-th': 'cond-mat.mtrl-sci',\n",
       " 'patt-sol': 'nlin.PS',\n",
       " 'plasm-ph': 'physics.plasm-ph',\n",
       " 'q-alg': 'math.QA',\n",
       " 'solv-int': 'nlin.SI',\n",
       " 'supr-con': 'cond-mat.supr-con'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'adap-org' in label_dict_old, 'adap-org' in label_dict_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
